{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voice Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Parselmouth, Praat's Voice Report (which is accessible in from its Sound Viewer's menu: Pulses->Voice report) can be reproduced in Python using Parselmouth. This example steps through the process to obtain the identical voice analysis report.\n",
    "\n",
    "We use an audio recording of someone saying *\"Two\"*: [2_b.wav](audio/2_b.wav) and pick the voiced audio samples within. Note: Ideally, your acoustic signal should be of a sustained phonation (of your choice of vowel). Anyhow, here is what Praat produces after it runs Voice Analysis:\n",
    "\n",
    "```\n",
    "-- Voice report for 1. Sound 2_b --\n",
    "Date: Mon Feb 22 09:50:04 2021\n",
    "\n",
    "Time range of SELECTION\n",
    "   From 0.179649 to 0.387611 seconds (duration: 0.207962 seconds)\n",
    "Pitch:\n",
    "   Median pitch: 102.297 Hz\n",
    "   Mean pitch: 104.189 Hz\n",
    "   Standard deviation: 15.830 Hz\n",
    "   Minimum pitch: 84.573 Hz\n",
    "   Maximum pitch: 153.580 Hz\n",
    "Pulses:\n",
    "   Number of pulses: 22\n",
    "   Number of periods: 21\n",
    "   Mean period: 9.653643E-3 seconds\n",
    "   Standard deviation of period: 1.359495E-3 seconds\n",
    "Voicing:\n",
    "   Fraction of locally unvoiced frames: 0   (0 / 63)\n",
    "   Number of voice breaks: 0\n",
    "   Degree of voice breaks: 0   (0 seconds / 0 seconds)\n",
    "Jitter:\n",
    "   Jitter (local): 2.786%\n",
    "   Jitter (local, absolute): 268.942E-6 seconds\n",
    "   Jitter (rap): 0.606%\n",
    "   Jitter (ppq5): 0.657%\n",
    "   Jitter (ddp): 1.819%\n",
    "Shimmer:\n",
    "   Shimmer (local): 11.646%\n",
    "   Shimmer (local, dB): 1.494 dB\n",
    "   Shimmer (apq3): 2.097%\n",
    "   Shimmer (apq5): 5.126%\n",
    "   Shimmer (apq11): 3.040%\n",
    "   Shimmer (dda): 6.292%\n",
    "Harmonicity of the voiced parts only:\n",
    "   Mean autocorrelation: 0.948082\n",
    "   Mean noise-to-harmonics ratio: 0.070337\n",
    "   Mean harmonics-to-noise ratio: 15.956 dB\n",
    "```\n",
    "\n",
    "To replicate these results in Python/Parselmouth, we will utilize the following classes therein: `parselmouth.Sound`, `parselmouth.Pitch`, and `parselmouth.PointProcess`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0. Get necessary packages\n",
    "\n",
    "We start out by importing `parselmouth` and other Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import parselmouth\n",
    "\n",
    "from os import path\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Read the acoustic data and set analysis range\n",
    "\n",
    "Fist thing to do is to open and read in the audio file and set analysis window (or domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load acoustic data from the WAV file\n",
    "wavfile = \"audio/2_b.wav\"\n",
    "sound = parselmouth.Sound(wavfile)\n",
    "\n",
    "# Define the window\n",
    "tlim = (0.179649, 0.387611)\n",
    "\n",
    "# Plot the waveform and analysis window\n",
    "plt.plot(sound.xs(), sound.values.T)\n",
    "plt.axvline(tlim[0],ls=\":\",c=\"tab:red\")\n",
    "plt.axvline(tlim[1],ls=\":\",c=\"tab:red\")\n",
    "plt.xlim((sound.xmin, sound.xmax))\n",
    "plt.xlabel(\"time [s]\")\n",
    "plt.ylabel(\"amplitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create `Pitch` and `PointProcess` objects\n",
    "\n",
    "Next, generate `Pitch` and `PointProcess` objects from `sound`. `Pitch` objects contain measurements of the fundamental frequency and its strength in equispaced frames (default: 33.33-ms wide) while `PointProcess` objects contain a series of time markers, which separates observed voice periods.\n",
    "\n",
    "Note that there are 2 algorithms to generate `Pitch` object from `Sound` object: `to_pitch_ac()` and `to_pitch_cc()`. The former is based on autocorrelation method while the latter is based on cross-correlation. Praat recommends using the cross-correlation method for voice analysis.\n",
    "\n",
    "Likewise, there are 3 methods to generate `PointProcess` object from `Pitch` object: (1) purely based on the pitch estimates, (2) use `Sound` samples to obtain more accurate cycle boundaries using cross-correlation, and (3) like (2) but use less-accurate (but faster) peak-picking method. Again, for the best results, use the cross-correlation based method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate Pitch and PointProcess objects\n",
    "pitch = sound.to_pitch_cc()\n",
    "pulses = pitch.to_point_process_cc(sound)\n",
    "\n",
    "# Compute instantaneous fundamental frequency estimates\n",
    "tb = np.array(pulses)\n",
    "f0 = 1/np.diff(tb)\n",
    "tp = (tb[:-1]+tb[1:])/2.0 # center of the cycle\n",
    "\n",
    "# plot the pitch contour and cycles\n",
    "plt.subplot(2,1,1,xlim=tlim,ylabel=\"fundamental frequency (Hz)\")\n",
    "plt.plot(pitch.xs(), pitch.selected_array[\"frequency\"])\n",
    "plt.plot(tp,f0,'.')\n",
    "for t in tb:\n",
    "    plt.axvline(t,ls=\":\",c=\"tab:blue\")\n",
    "plt.legend((\"`Pitch`\",\"Instantaneous $F_0$\"))\n",
    "\n",
    "plt.subplot(2,1,2,xlim=tlim,ylabel=\"amplitude\",xlabel=\"time [s]\")\n",
    "plt.plot(sound.xs(), sound.values.T,color=\"gray\")\n",
    "for t in tb:\n",
    "    plt.axvline(t,ls=\":\",c=\"tab:blue\")\n",
    "plt.legend((\"acoustic data\", \"cycle boundaries\",))\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "## Step 3: Voice Report Header\n",
    "\n",
    "Now we are ready to produce our own report. First, the trivial stuff at the top..."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"-- Voice report for 1. {path.basename(wavfile)[:-4]} --\")\n",
    "print(f\"Date: {datetime.now().strftime('%c')}\")\n",
    "print(f\"Time range of SELECTION\")\n",
    "print(f\"    From {tlim[0]:6g} to {tlim[1]:6g} seconds (duration: {tlim[1]-tlim[0]:6g} seconds)\")"
   ]
  },
  {
   "source": [
    "## Step 4: Pitch Entry\n",
    "\n",
    "Pitch statistics are obtained from `pitch` object. Note `tlim` is unpacked in the function arguments to provide the 2nd (`from_time`) and 3rd `end_time` arguments. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Pitch:\")\n",
    "print(f\"   Median pitch: {pitch.get_quantile(0.5,*tlim):0.3f} Hz\")\n",
    "print(f\"   Mean pitch: {pitch.get_mean(*tlim):0.3f} Hz\")\n",
    "print(f\"   Standard deviation: {pitch.get_standard_deviation(*tlim):0.3f} Hz\")\n",
    "print(f\"   Minimum pitch: {pitch.get_minimum(*tlim):0.3f} Hz\")\n",
    "print(f\"   Maximum pitch: {pitch.get_maximum(*tlim):0.3f} Hz\")"
   ]
  },
  {
   "source": [
    "## Step 5: Pulse Entry\n",
    "\n",
    "Pulse (or cycle) statistics are obtained from `pulses` object. \n",
    "\n",
    "Be aware that `PointProcess.get_number_of_points()` always returns the total number of points and not over the analysis window. If this information is critical, extract the target audio data first via `sound.extract_part(...)` then run the rest of the analysis on it.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pulses:\")\n",
    "print(f\"   Number of pulses: {pulses.get_number_of_points()}\")\n",
    "print(f\"   Number of periods: {pulses.get_number_of_periods(*tlim)}\")\n",
    "print(f\"   Mean period: {pulses.get_mean_period(*tlim):0.6E} seconds\")\n",
    "print(f\"   Standard deviation of period: {pulses.get_stdev_period(*tlim):0.6E} seconds\")"
   ]
  },
  {
   "source": [
    "## Step 6: Voicing Entry\n",
    "\n",
    "Unvoiced period analysis is performed by `Pitch.get_fraction_of_locally_unvoiced_frames(...)` while\n",
    "voice break analysis is performed by `PointProcess.get_count_and_fraction_of_voice_breaks(...)`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lu_frac, lu_num, lu_den = pitch.get_fraction_of_locally_unvoiced_frames(*tlim)\n",
    "n, deg, Tu, Tt = pulses.get_count_and_fraction_of_voice_breaks(*tlim)\n",
    "\n",
    "print(\"Voicing:\")\n",
    "print(f\"   Fraction of locally unvoiced frames: {lu_frac}   ({lu_num} / {lu_den})\")\n",
    "print(f\"   Number of voice breaks: {n}\")\n",
    "print(f\"   Degree of voice breaks: {deg}   ({Tu} seconds / {Tt} seconds)\")"
   ]
  },
  {
   "source": [
    "## Step 7: Jitter Entry\n",
    "\n",
    "Jitters are measured by `PointProcess.get_jitter_xxx(...)` methods"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Jitter:\")\n",
    "print(f\"   Jitter (local): {pulses.get_jitter_local(*tlim)*100:0.3f}%\")\n",
    "print(f\"   Jitter (local, absolute): {pulses.get_jitter_local_absolute(*tlim):0.5E} seconds\") # shows up as \"E-4\"  rather than \"E-6\"\n",
    "print(f\"   Jitter (rap): {pulses.get_jitter_rap(*tlim)*100:0.3f}%\")\n",
    "print(f\"   Jitter (ppq5): {pulses.get_jitter_ppq5(*tlim)*100:0.3f}%\")\n",
    "print(f\"   Jitter (ddp): {pulses.get_jitter_ddp(*tlim)*100:0.3f}%\")"
   ]
  },
  {
   "source": [
    "## Step 8: Shimmer Entry\n",
    "\n",
    "Shimmers are measured by `PointProcess.get_shimmer_xxx(...)` methods and requires the source `Sound` object"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shimmer:\")\n",
    "print(f\"   Shimmer (local): {pulses.get_shimmer_local(sound,*tlim)*100:.3f}%\")\n",
    "print(f\"   Shimmer (local, dB): {pulses.get_shimmer_local_dB(sound,*tlim):.3f} dB\")\n",
    "print(f\"   Shimmer (apq3): {pulses.get_shimmer_local_apq3(sound,*tlim)*100:.3f}%\")\n",
    "print(f\"   Shimmer (apq5): {pulses.get_shimmer_local_apq5(sound,*tlim)*100:.3f}%\")\n",
    "print(f\"   Shimmer (apq11): {pulses.get_shimmer_local_apq11(sound,*tlim)*100:.3f}%\")\n",
    "print(f\"   Shimmer (dda): {pulses.get_shimmer_local_dda(sound,*tlim)*100:.3f}%\")"
   ]
  },
  {
   "source": [
    "## Step 9: Harmonicity Entry\n",
    "\n",
    "The last section of the report contains the harmonicity analysis. This analysis is done with `Pitch` object, specifically with its `get_mean_strength(...)` method"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Harmonicity of the voiced parts only:\")\n",
    "print(f\"   Mean autocorrelation: {pitch.get_mean_strength('ac', *tlim):.6f}\")\n",
    "print(f\"   Mean noise-to-harmonics ratio: {pitch.get_mean_strength('nhr', *tlim):.6f}\")\n",
    "print(f\"   Mean harmonics-to-noise ratio: {pitch.get_mean_strength('hnr_db', *tlim):.3f}\")"
   ]
  },
  {
   "source": [
    "## Summary\n",
    "\n",
    "This notebook presents an example of how to run the full Praat Voice Analysis and print its report as you would see them in Praat UI. \n",
    "\n",
    "Obviously, simply replicating what Praat does exactly is not the strength of `Parselmouth`. With Python and `Parselmouth` package, you can:\n",
    "\n",
    "- Compute and record only the voice measures of your interest\n",
    "- Directly write the measurements to a file\n",
    "- Batch process multiple input files\n",
    "- Combine Praat parameters with other voice parameters\n",
    "- Add preprocessing algorithm to auto-select analysis window (i.e., auto-picking `tlim`)\n",
    "\n",
    "Happy Parselmouth'ing!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}